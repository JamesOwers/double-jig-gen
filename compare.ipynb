{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from typing import Dict, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from double_jig_gen.data import (\n",
    "    ABCDataset,\n",
    "    get_folkrnn_dataloaders,\n",
    "    pad_batch,\n",
    "    get_oneills_dataloaders\n",
    ")\n",
    "from double_jig_gen.tokenizers import Tokenizer\n",
    "from double_jig_gen.models import SimpleRNN, Transformer\n",
    "from double_jig_gen.utils import get_model_from_checkpoint\n",
    "\n",
    "logging.basicConfig()\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_most_recent_path(paths):\n",
    "    \"\"\"Returns the most recently created path from a list of paths.\n",
    "\n",
    "    Args:\n",
    "        paths: a list of paths to check.\n",
    "\n",
    "    Returns:\n",
    "        the most recently created path.\n",
    "    \"\"\"\n",
    "    return max(paths, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = list(range(23, 31))\n",
    "# expt_ids.remove(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(expt_dirpath):    \n",
    "    checkpoint_dirpath = Path(expt_dirpath, \"checkpoints\")\n",
    "    ckpt_paths = [\n",
    "        path for path in checkpoint_dirpath.iterdir() if str(path).endswith(\".ckpt\")\n",
    "    ]\n",
    "    latest_ckpt_path = _get_most_recent_path(ckpt_paths)\n",
    "\n",
    "    experiment_args_path = Path(expt_dirpath, \"experiment_args.yaml\")\n",
    "    # The yaml file has lowcase trainer in tag:\n",
    "    # python/name:pytorch_lightning.trainer.trainer._gpus_arg_default\n",
    "    # so loading fails with SafeLoader, have to use BaseLoader\n",
    "    # args = pl.core.saving.load_hparams_from_yaml(str(experiment_args_path))\n",
    "    with open(str(experiment_args_path), 'r') as fh:\n",
    "        args_dict = yaml.load(fh, Loader=yaml.BaseLoader)\n",
    "    args_dict['latest_checkpoint'] = latest_ckpt_path\n",
    "    args_dict[\"checkpoint_epoch\"] = int(\n",
    "        ''.join(re.findall(r\"\\d+\", str(latest_ckpt_path.name)))\n",
    "    )\n",
    "    args = Namespace()\n",
    "    vars(args).update(args_dict)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_path = \"/disk/scratch_fast\"\n",
    "expt_dirpath = Path(f\"{scratch_path}/s0816700/logs/lightning_logs\")\n",
    "expt_dirs = [\n",
    "    Path(expt_dirpath, f\"version_{expt_id}\") for expt_id in expt_ids\n",
    "]\n",
    "args = {\n",
    "    str(dirpath): vars(get_args(dirpath)) for dirpath in expt_dirs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_configs = pd.DataFrame.from_dict(args, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"dataset\",\n",
    "    \"checkpoint_epoch\",\n",
    "    \"early_stopping_patience\",\n",
    "    \"val_prop\", \n",
    "    \"val_shuffle\",\n",
    "    \"batch_size\",\n",
    "    \"model_load_from_checkpoint\",\n",
    "    \"latest_checkpoint\",\n",
    "    \"seed\",\n",
    "    \"model\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_configs[\"model\"] = expt_configs.latest_checkpoint.apply(\n",
    "    lambda ckpt_path: SimpleRNN.load_from_checkpoint(checkpoint_path=str(ckpt_path))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_configs[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, vld, tst = get_oneills_dataloaders(\n",
    "    \"/disk/scratch_fast/s0816700/data/oneills/oneills_reformat.abc\",\n",
    "    \"/disk/scratch_fast/s0816700/data/folk-rnn/data_v3_vocabulary.txt\",\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_trainer = pl.Trainer(\n",
    "    gpus='7,',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(\n",
    "    rnn_type=\"LSTM\",\n",
    "    ntoken=106,\n",
    "    ninp=256,\n",
    "    nhid=512,\n",
    "    nlayers=3,\n",
    "    model_batch_size=16,\n",
    "    dropout=.6,\n",
    "    embedding_padding_idx=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_loss_per_token(model, dataloader, device):\n",
    "    model = model.to(device)\n",
    "#     print(dict(model.named_parameters()))\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    with torch.no_grad():\n",
    "        for padded_batch, seq_lens in dataloader:\n",
    "            padded_batch = padded_batch.to(device)\n",
    "            outputs = model(padded_batch, seq_lens)\n",
    "            loss_total += model.loss(outputs, padded_batch).item()\n",
    "    return loss_total / len(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_avg_loss_per_token(model, tst, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = {}\n",
    "for log_dir, log_data in expt_configs.iterrows():\n",
    "    model = log_data.model\n",
    "    test_res[log_dir] = get_avg_loss_per_token(model, tst, 'cuda')\n",
    "    \n",
    "#     model.to('cuda')\n",
    "#     print({name: data.shape for name, data in model.named_parameters()})\n",
    "    # WEIRD CUDA ERRORS...\n",
    "#     test_res[ckpt_path] = lightning_trainer.test(\n",
    "#         model,\n",
    "#         test_dataloaders=tst,\n",
    "#         ckpt_path=ckpt_path,\n",
    "#     )\n",
    "#     test_res[ckpt_path] = get_avg_loss_per_token(model, tst, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_configs[\"test_loss\"] = pd.Series(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"test_loss\",\n",
    "    \"checkpoint_epoch\",\n",
    "    \"val_prop\", \n",
    "    \"val_shuffle\",\n",
    "    \"batch_size\",\n",
    "    \"model_load_from_checkpoint\",\n",
    "    \"seed\",\n",
    "]\n",
    "expt_configs[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
