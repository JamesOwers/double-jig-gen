{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from typing import Dict, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from double_jig_gen.data import ABCDataset, get_folkrnn_dataloaders, pad_batch\n",
    "from double_jig_gen.tokenizers import Tokenizer\n",
    "from double_jig_gen.models import SimpleRNN, Transformer\n",
    "from double_jig_gen.utils import get_model_from_checkpoint\n",
    "\n",
    "logging.basicConfig()\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_most_recent_path(paths):\n",
    "    \"\"\"Returns the most recently created path from a list of paths.\n",
    "\n",
    "    Args:\n",
    "        paths: a list of paths to check.\n",
    "\n",
    "    Returns:\n",
    "        the most recently created path.\n",
    "    \"\"\"\n",
    "    return max(paths, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lightning_logs/version_54/experiment_args.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3484fc7450b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# so loading fails with SafeLoader, have to use BaseLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# args = pl.core.saving.load_hparams_from_yaml(str(experiment_args_path))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_args_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0margs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0margs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_load_from_checkpoint'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_ckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lightning_logs/version_54/experiment_args.yaml'"
     ]
    }
   ],
   "source": [
    "expt_id = 54\n",
    "# scratch_path = \"/disk/scratch_fast\"\n",
    "# expt_dirpath = Path(f\"{scratch_path}/s0816700/logs/lightning_logs/version_{expt_id}\")\n",
    "expt_dirpath = Path(f\"lightning_logs/version_{expt_id}\")\n",
    "checkpoint_dirpath = Path(expt_dirpath, \"checkpoints\")\n",
    "ckpt_paths = [\n",
    "    path for path in checkpoint_dirpath.iterdir() if str(path).endswith(\".ckpt\")\n",
    "]\n",
    "latest_ckpt_path = _get_most_recent_path(ckpt_paths)\n",
    "\n",
    "experiment_args_path = Path(expt_dirpath, \"experiment_args.yaml\")\n",
    "# The yaml file has lowcase trainer in tag:\n",
    "# python/name:pytorch_lightning.trainer.trainer._gpus_arg_default\n",
    "# so loading fails with SafeLoader, have to use BaseLoader\n",
    "# args = pl.core.saving.load_hparams_from_yaml(str(experiment_args_path))\n",
    "with open(str(experiment_args_path), 'r') as fh:\n",
    "    args_dict = yaml.load(fh, Loader=yaml.BaseLoader)\n",
    "args_dict['model_load_from_checkpoint'] = latest_ckpt_path\n",
    "args = Namespace()\n",
    "vars(args).update(args_dict)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = Path(args.model_load_from_checkpoint).expanduser().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS: Dict[str, Union[Type[SimpleRNN], Type[Transformer]]] = {\n",
    "    \"rnn\": SimpleRNN,\n",
    "    \"transformer\": Transformer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelClass = MODELS[args.model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_from_checkpoint(ckpt_path, ModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict['encoder_layer.weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show that something has been learned! The first four tokens are:\n",
    "* 0: `<pad>` - padding token\n",
    "* 1: `<unk>` - unknown/rare token\n",
    "* 2: `<s>` - start sequence\n",
    "* 3: `</s>` - end sequence\n",
    "\n",
    "The encoder weights show that: nothing is learned for `<pad>`, `<unk>`, and `</s>` as they have their initialised weights near zero; something is learned for `<s>` as these have weights. This is as expected because nothing should follow pad and end seq, and there are no unk tokens in this dataset!\n",
    "\n",
    "The decoder weights show the same, except nothing is learned for `<s>`, and something for `</s>`. Again, this is expected since the start sequence token should never be predicted, and the end sequence token should be predicted a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_enc = param_dict['encoder_layer.weight'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_enc)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_enc[:4], aspect='auto', interpolation='none')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_dec = param_dict['decoder_layer.weight'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_dec)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_dec[:4], aspect='auto', interpolation='none')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_ID = 7\n",
    "LOGGER.info(f\"Changing to device {DEVICE_ID}\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{DEVICE_ID}\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_folkrnn_dataloaders(\n",
    "    args.folkrnn_data_path,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = dataloaders[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = valid_dataloader.dataset.tokenizer\n",
    "# token_sequences = [\n",
    "#     [\"<s>\"],\n",
    "#     [\"<s>\", \"M:6/8\"],\n",
    "#     [\"<s>\", \"M:6/8\", \"K:mix\"],\n",
    "#     [\"\"]\n",
    "# ]\n",
    "token_sequences = (\n",
    "    [[\"<s>\"]] * 20 +\n",
    "    [[\"<s>\", \"M:6/8\"]] * 5 + \n",
    "    [[\"<s>\", \"M:6/8\", \"K:mix\"]] * 5\n",
    ")\n",
    "priming_dataset = ABCDataset(\n",
    "    tunes=token_sequences,\n",
    "    tokens=valid_dataloader.dataset.tokens,\n",
    "    wrap_tunes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_idx = valid_dataloader.dataset.tokenizer.pad_token_index\n",
    "pad_priming_batch = lambda batch: pad_batch(batch, pad_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priming_loader = DataLoader(\n",
    "    priming_dataset,\n",
    "    batch_size=len(priming_dataset),\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    "    collate_fn=pad_priming_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token_idx = tokenizer.end_token_index\n",
    "max_seq_len = 1000\n",
    "for batch_item in priming_loader:\n",
    "    padded_data, seq_lens = batch_item\n",
    "    seq_lens = np.array(seq_lens)\n",
    "    padded_data = padded_data.to(device)\n",
    "    still_generating = np.array([True] * padded_data.shape[1])\n",
    "    for ii in range(max_seq_len):\n",
    "        next_tokens = model.generate_next_token(\n",
    "            padded_data[:, still_generating], \n",
    "            seq_lens[still_generating],\n",
    "            topk=5\n",
    "        )\n",
    "        padded_data = F.pad(\n",
    "            input=padded_data,\n",
    "            pad=(0, 0, 0, 1),  # Pad bottom\n",
    "            mode=\"constant\",\n",
    "            value=pad_token_idx,\n",
    "        )\n",
    "        padded_data[seq_lens[still_generating], still_generating] = next_tokens\n",
    "        if all(padded_data[-1] == 0):\n",
    "            padded_data = padded_data[:-1]\n",
    "        seq_lens[still_generating] += 1\n",
    "        last_tokens = padded_data[seq_lens - 1, range(padded_data.shape[1])]\n",
    "        still_generating = np.array((last_tokens != end_token_idx).tolist())\n",
    "        if still_generating.sum() == 0:\n",
    "            break\n",
    "        \n",
    "    generations = [tokenizer.untokenize(seq.cpu()) for seq in padded_data.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gen_str(gen_str):\n",
    "    gen_str = gen_str[4:-5]\n",
    "    meter, key, tune = gen_str.split(' ', 2)\n",
    "    tune = re.sub(r\" (/?[0-9])\", r\"\\1\", tune)\n",
    "    return f\"{meter.strip()}\\n{key.strip()}\\n{tune.strip()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, gen in enumerate(generations):\n",
    "    print(clean_gen_str(' '.join(gen[:seq_lens[idx]])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.end_token_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make 10,000!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sequences = (\n",
    "    [[\"<s>\"]] * 10000\n",
    ")\n",
    "priming_dataset = ABCDataset(\n",
    "    tunes=token_sequences,\n",
    "    tokens=valid_dataloader.dataset.tokens,\n",
    "    wrap_tunes=False,\n",
    ")\n",
    "priming_loader = DataLoader(\n",
    "    priming_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=False,\n",
    "    collate_fn=pad_priming_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gens = []\n",
    "all_lens = []\n",
    "for batch_item in priming_loader:\n",
    "    padded_data, seq_lens = batch_item\n",
    "    padded_data = padded_data.to(device)\n",
    "    generations, gen_seq_lens = model.generate_tunes(\n",
    "        padded_data,\n",
    "        seq_lens,\n",
    "        max_nr_generation_steps=1000,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    all_gens.extend(generations)\n",
    "    all_lens.extend(gen_seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_gens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('data', 'output')\n",
    "Path(out_dir, 'folkrnn').mkdir(parents=True, exist_ok=True)\n",
    "Path(out_dir, 'abc').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (gen, gen_len) in tqdm(enumerate(zip(all_gens, all_lens)), total=10000):\n",
    "    filename = f\"tune_{idx+1:05d}\"\n",
    "    gen_str = ' '.join(gen[:gen_len])\n",
    "    gen_str = gen_str[4:-5]\n",
    "    meter, key, tune = gen_str.split(' ', 2)\n",
    "    \n",
    "    folkrnn_outpath = Path(out_dir, 'folkrnn', filename)\n",
    "    with open(str(folkrnn_outpath), 'w') as fh:\n",
    "        fh.write(f\"{meter.strip()}\\n{key.strip()}\\n{tune.strip()}\")\n",
    "    \n",
    "    tune = re.sub(r\" (/?[0-9])\", r\"\\1\", tune)\n",
    "    key = key[:2] + \"C\" + key[2:]\n",
    "    abc_outpath = Path(out_dir, 'abc', f\"{filename}.abc\")\n",
    "    with open(str(abc_outpath), 'w') as fh:\n",
    "        fh.write(f\"X:{idx+1}\\n{meter.strip()}\\n{key.strip()}\\n{tune.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
