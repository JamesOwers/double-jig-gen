{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import music21\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from double_jig_gen.data import (\n",
    "    ABCDataset,\n",
    "    default_pad_batch,\n",
    "    fix_encoding_errors,\n",
    "    get_oneills_dataloaders,\n",
    "    get_folkrnn_dataloaders,\n",
    "    remove_quoted_strings,\n",
    ")\n",
    "from double_jig_gen.tokenizers import Tokenizer, ABCTune, ABCTuneError\n",
    "\n",
    "logging.basicConfig()\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_ID = 7\n",
    "SCRATCH_NAME = \"scratch_ssd\"\n",
    "DATA_HOME = f\"/disk/{SCRATCH_NAME}/s0816700/data\"\n",
    "# DATA_HOME = \"data\"\n",
    "DATA_PATH = f\"{DATA_HOME}/folk-rnn/data_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! scripts/dj-gen-get-data {DATA_HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â https://github.com/IraKorshunova/folk-rnn/blob/master/configurations/config5.py\n",
    "ONE_HOT = True\n",
    "EMBEDDING_SIZE = 256  # is ignored if one_hot=True\n",
    "NUM_LAYERS = 3\n",
    "RNN_SIZE = 512\n",
    "DROPOUT = 0.5\n",
    "\n",
    "LEARNING_RATE = 0.003\n",
    "LEARNING_RATE_DECAY_AFTER = 20\n",
    "LEARNING_RATE_DECAY = 0.97\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MAX_EPOCH = 100\n",
    "GRAD_CLIPPING = 5\n",
    "VALIDATION_FRACTION = 0.05\n",
    "VALIDATE_EVERY = 1000  # iterations\n",
    "\n",
    "SAVE_EVERY = 10  # epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER.info(f\"Changing to device {DEVICE_ID}\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{DEVICE_ID}\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOGGER.info(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read FolkRNN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NR_TUNES = 1_000\n",
    "NR_TUNES = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH, 'r') as fh:\n",
    "    raw_folkrnn_data = fh.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_folkrnn_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_data = raw_folkrnn_data.split(\"\\n\\n\")[0]\n",
    "abc_tune = ABCTune(\n",
    "    abc_data,\n",
    "    pianoroll_divisions_per_quarternote=2,\n",
    "    min_pitch=None,\n",
    "    min_time=None,\n",
    "    transpose_to_pitchclass=\"C\",\n",
    ")\n",
    "abc_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_tune.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_data_list = raw_folkrnn_data.split(\"\\n\\n\")\n",
    "len(abc_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tune(tune_str):\n",
    "    return fix_encoding_errors(remove_quoted_strings(tune_str))\n",
    "\n",
    "clean_abc_data = [clean_tune(tune_str) for tune_str in abc_data_list[:NR_TUNES]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handle cleaning fails (normally a singleton double quote in input data)\n",
    "cleaning_fails = [\n",
    "    (ii, abc_data_list[ii])\n",
    "    for ii, tune in enumerate(abc_data_list)\n",
    "    if '\"' in clean_tune(tune)\n",
    "]\n",
    "# for idx, tune in cleaning_fails:\n",
    "#     print(f\"tune: {idx=}\")\n",
    "#     print(tune)\n",
    "#     print(\"clean_tune=\")\n",
    "#     print(clean_tune(tune))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read with Music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abc_tune(abc_data):\n",
    "    try:\n",
    "        abc_tune = ABCTune(\n",
    "            abc_data,\n",
    "            pianoroll_divisions_per_quarternote=12,\n",
    "            min_pitch=0,\n",
    "            min_time=0,\n",
    "            transpose_to_pitchclass=\"C\",\n",
    "        )\n",
    "    except ABCTuneError as e:\n",
    "        msg = f\"Raised error: {repr(e)}\\nNot including {abc_data}.\"\n",
    "        LOGGER.warning(msg)\n",
    "        abc_tune = msg\n",
    "    except Exception as e:\n",
    "        msg = f\"unexpected error: {repr(e)}\\nNot including {abc_data}.\"\n",
    "        LOGGER.warning(msg)\n",
    "        abc_tune = msg\n",
    "    return abc_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: profile this\n",
    "tunes = [get_abc_tune(abc_data) for abc_data in tqdm(clean_abc_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove import failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tunes = [tune for tune in tunes if not isinstance(tune, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_tunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tunes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bum_tunes = [(idx, tune) for idx, tune in enumerate(tunes) if isinstance(tune, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bum_tunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\", \".join([str(idx) for idx, msg in bum_tunes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for idx, msg in bum_tunes:\n",
    "#     print(idx)\n",
    "#     print(msg)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude long tunes\n",
    "We will need to batch all the data. Exclude very long examples for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunes_as_token_lists = [\n",
    "    [tok.src for tok in tune._abc_handler.tokens]\n",
    "    for tune in tqdm(clean_tunes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "tunes_as_token_lists[idx][:5] + [\"...\"] + tunes_as_token_lists[idx][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "tunes_as_token_lists[idx][:5] + [\"...\"] + tunes_as_token_lists[idx][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_lens = np.array([len(t) for t in tunes_as_token_lists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "sns.histplot(tune_lens)\n",
    "plt.subplot(132)\n",
    "sns.kdeplot(tune_lens)\n",
    "plt.subplot(133)\n",
    "sns.ecdfplot(tune_lens)\n",
    "plt.suptitle(f\"Number of tokens for all {len(tunes_as_token_lists)} tunes\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = .95\n",
    "nr_kept = int(np.rint(len(tune_lens)*pct))\n",
    "val_pct = sorted(tune_lens)[nr_kept - 1]\n",
    "val_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_long_tunes = [tune for tune in tunes_as_token_lists if len(tune) <= val_pct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_lens = [len(t) for t in not_long_tunes]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "sns.histplot(tune_lens)\n",
    "plt.subplot(132)\n",
    "sns.kdeplot(tune_lens)\n",
    "plt.subplot(133)\n",
    "sns.ecdfplot(tune_lens)\n",
    "plt.suptitle(f\"Tunes shorter than or equal to {val_pct} tokens\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude very short tunes\n",
    "They are likely errors / not representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_tune_length = 8*6 + 4  # 8 bars with 6 tokens plus 4 starting tokens\n",
    "min_tune_length = 60  # a bit harsher\n",
    "print(f\"{min_tune_length=}\")\n",
    "short_tunes = [tune for tune in not_long_tunes if len(tune) < min_tune_length]\n",
    "print(f\"excluding {len(short_tunes)} short tunes (length < {min_tune_length})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_tunes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_length_tunes = [\n",
    "    tune\n",
    "    for tune in not_long_tunes\n",
    "    if len(tune) >= min_tune_length\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_lens = [len(tune) for tune in mid_length_tunes]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "sns.histplot(tune_lens)\n",
    "plt.subplot(132)\n",
    "sns.kdeplot(tune_lens)\n",
    "plt.subplot(133)\n",
    "sns.ecdfplot(tune_lens)\n",
    "plt.suptitle(f\"Tunes longer than or equal to {min_tune_length} tokens\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace titles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunes = mid_length_tunes\n",
    "title_token = \"T: Title\"\n",
    "tunes = [\n",
    "    [title_token if tok.startswith(\"T:\") else tok for tok in tune]\n",
    "    for tune in tunes\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntunes = len(tunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvalid_tunes = ntunes * VALIDATION_FRACTION\n",
    "# round to a multiple of batch_size\n",
    "nvalid_tunes = BATCH_SIZE * max(\n",
    "    1,\n",
    "    int(np.rint(nvalid_tunes / BATCH_SIZE))\n",
    ")\n",
    "nvalid_tunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "valid_idxs = rng.choice(np.arange(ntunes), nvalid_tunes, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain_tunes = ntunes - nvalid_tunes\n",
    "train_idxs = np.delete(np.arange(ntunes), valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tunes = [tune for idx, tune in enumerate(tunes) if idx in valid_idxs]\n",
    "train_tunes = [tune for idx, tune in enumerate(tunes) if idx in train_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handle ornaments and weird metadata\n",
    "tokens_set = set(\n",
    "    tok\n",
    "    for tune in train_tunes  # Note that we're only tokenizing the training data\n",
    "    for tok in tune\n",
    ")\n",
    "vocab_size = len(tokens_set)\n",
    "print(f\"vocabulary size: {vocab_size}\")\n",
    "print(f\"vocabulary (each token separated by a space): \\n{' '.join(sorted(tokens_set))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = ABCDataset(tunes=valid_tunes, tokens=tokens_set)\n",
    "train_dataset = ABCDataset(tunes=train_tunes, tokens=tokens_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get frequency of each and exclude infrequent\n",
    "# TODO: handle chords!\n",
    "# TODO: handle timings (e.g. a number after a note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(tokens=tokens_set)\n",
    "tokenizer = train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tunes = [tokenizer.tokenize(tune) for tune in tqdm(tunes_as_token_lists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "tunes_as_token_lists[idx][:5] + [\"...\"] + tunes_as_token_lists[idx][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tunes[idx][:5] + [\"...\"] + tokenized_tunes[idx][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    tokenizer.untokenize(tokenized_tunes[idx][:5]) +\n",
    "    [\"...\"] + \n",
    "    tokenizer.untokenize(tokenized_tunes[idx][-5:])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching in the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=default_pad_batch,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    print(batch[0].size())\n",
    "    print(max(batch[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=default_pad_batch,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from double_jig_gen.models import SimpleRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == \"cuda\":\n",
    "    max_epochs = 200\n",
    "else:\n",
    "    max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning_trainer = pl.Trainer(gpus='1,')\n",
    "\n",
    "lightning_trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    gpus=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(\n",
    "    rnn_type=\"LSTM\",\n",
    "    ntoken=train_dataset.vocabulary_size,\n",
    "    ninp=EMBEDDING_SIZE,\n",
    "    nhid=RNN_SIZE,\n",
    "    nlayers=NUM_LAYERS,\n",
    "    model_batch_size=BATCH_SIZE,\n",
    "    dropout=DROPOUT,\n",
    "    embedding_padding_idx=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lightning_trainer.fit(\n",
    "    model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict['encoder_layer.weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show that something has been learned! The first four tokens are:\n",
    "* 0: `<pad>` - padding token\n",
    "* 1: `<unk>` - unknown/rare token\n",
    "* 2: `<s>` - start sequence\n",
    "* 3: `</s>` - end sequence\n",
    "\n",
    "The encoder weights show that: nothing is learned for `<pad>`, ~`<unk>`~, and `</s>` as they have their initialised weights near zero; something is learned for `<s>` as these have weights. This is as expected because nothing should follow pad and end seq~, and there are no unk tokens in this dataset~! ~All pieces start with an `<unk>` token - the title, so this will normally predict a time signature next.~\n",
    "\n",
    "The decoder weights show the same, except nothing is learned for `<s>`, and something for `</s>`. Again, this is expected since the start sequence token should never be predicted, and the end sequence token should be predicted a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_enc = param_dict['encoder_layer.weight'].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_enc)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_enc[:4], aspect='auto', interpolation='none')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_dec = param_dict['decoder_layer.weight'].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_dec)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(W_dec[:4], aspect='auto', interpolation='none')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = val_dataloader.dataset.tokenizer\n",
    "# token_sequences = [\n",
    "#     [\"<s>\"],\n",
    "#     [\"<s>\", \"M:6/8\"],\n",
    "#     [\"<s>\", \"M:6/8\", \"K:mix\"],\n",
    "#     [\"\"]\n",
    "# ]\n",
    "nr_of_each = 5\n",
    "token_sequences = (\n",
    "    [[\"blarg\"]] * nr_of_each +\n",
    "    [[\"<s>\"]] * nr_of_each +\n",
    "    [[\"<s>\", title_token]] * nr_of_each +\n",
    "    [[\"<s>\", title_token, \"M: 6/8\"]] * nr_of_each +\n",
    "    [[\"<s>\", title_token, \"M: 6/8\", \"L: 1/8\"]] * nr_of_each +\n",
    "    [[\"<s>\", title_token, \"M: 6/8\", \"L: 1/8\", \"K: Cmaj\"]] * nr_of_each\n",
    ")\n",
    "priming_dataset = ABCDataset(\n",
    "    tunes=token_sequences,\n",
    "    tokens=val_dataloader.dataset.tokens,\n",
    "    wrap_tunes=False,\n",
    ")\n",
    "pad_token_idx = val_dataloader.dataset.tokenizer.pad_token_index\n",
    "priming_loader = DataLoader(\n",
    "    priming_dataset,\n",
    "    batch_size=len(priming_dataset),\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=default_pad_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_item in tqdm(priming_loader, leave=True, desc=\"batch item\"):\n",
    "    padded_data, seq_lens = batch_item\n",
    "    print(type(padded_data), type(seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "end_token_idx = val_dataloader.dataset.tokenizer.end_token_index\n",
    "pad_token_idx = val_dataloader.dataset.tokenizer.pad_token_index\n",
    "assert pad_token_idx == 0\n",
    "max_seq_len = 1000\n",
    "\n",
    "# TODO: this seems rediculous...\n",
    "for batch_item in tqdm(priming_loader, leave=True, desc=\"batch item\"):\n",
    "    padded_data, seq_lens = batch_item\n",
    "    seq_lens = np.array(seq_lens)\n",
    "    padded_data = padded_data.to(device)\n",
    "    nr_seqs = padded_data.shape[1]\n",
    "    still_generating = np.array([True] * nr_seqs)\n",
    "    for ii in tqdm(list(range(max_seq_len)), leave=False, desc=\"seq position\"):\n",
    "        next_tokens = model.generate_next_token(\n",
    "            padded_data[:, still_generating], \n",
    "            seq_lens[still_generating],\n",
    "            topk=5\n",
    "        )\n",
    "        padded_data = F.pad(\n",
    "            input=padded_data,\n",
    "            pad=(0, 0, 0, 1),  # Pad bottom\n",
    "            mode=\"constant\",\n",
    "            value=0,\n",
    "        )\n",
    "        padded_data[seq_lens[still_generating], still_generating] = next_tokens\n",
    "        if all(padded_data[-1] == 0):\n",
    "            padded_data = padded_data[:-1]\n",
    "        seq_lens[still_generating] += 1\n",
    "        last_tokens = padded_data[seq_lens - 1, range(padded_data.shape[1])]\n",
    "        still_generating = np.array((last_tokens != end_token_idx).tolist())\n",
    "        if still_generating.sum() == 0:\n",
    "            break\n",
    "        \n",
    "generations = [tokenizer.untokenize(seq.cpu()) for seq in padded_data.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "#     \" \".join(gen[:10]) + \" ... \" + \" \".join(gen[(gen.index(\"</s>\")-10):gen.index(\"</s>\") + 1]) \n",
    "    \" \".join(gen[:10]) + \" ... \" + \" \".join(gen[(gen_len-10):gen_len]) \n",
    "    for gen, gen_len in zip(generations, seq_lens)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gen(gen_list):\n",
    "    start_token, title, meter, note_len, key, *tune, end_token = gen_list\n",
    "#     return f\"T: {title.strip()}\\n{meter.strip()}\\n{note_len.strip()}\\n{key.strip()}\\n{' '.join(tune)}\"\n",
    "    return f\"{title}\\n{meter}\\n{note_len}\\n{key}\\n{' '.join(tune)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=7\n",
    "trunc_generation = generations[idx][:seq_lens[idx]]\n",
    "print(trunc_generation)\n",
    "print(clean_gen(trunc_generation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.abcjs.net/abcjs-editor.html\n",
    "for idx, gen in enumerate(generations):\n",
    "    tune_str = clean_gen(gen[:seq_lens[idx]])\n",
    "    print(tune_str)\n",
    "    try:\n",
    "        tune = ABCTune(tune_str)\n",
    "#         tune.show()\n",
    "    except ABCTuneError:\n",
    "        LOGGER.warning(\"Tune does not compile\")\n",
    "        print(\"DOES NOT COMPILE\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on oneills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on_dataset = ABCDataset(\n",
    "#     filepath='data/oneills_reformat.abc',\n",
    "#     tokens=dataset.tokens\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(on_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_unk_toks = 0\n",
    "# for idx in range(len(on_dataset)):\n",
    "#     nr_unk_toks += (\n",
    "#         np.array(on_dataset[idx]) == on_dataset.tokenizer.unk_token_index\n",
    "#     ).sum()\n",
    "# nr_unk_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on_dataloader = DataLoader(\n",
    "#     on_dataset,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=True,\n",
    "#     collate_fn=rpad_batch,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=8,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "#     monitor=\"val_loss\",\n",
    "#     min_delta=0.00,\n",
    "#     patience=100,\n",
    "#     verbose=True,\n",
    "#     mode=\"min\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning_trainer = pl.Trainer(gpus='0,', deterministic=True, early_stop_callback=early_stop_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning_trainer.fit(\n",
    "#     model,\n",
    "#     train_dataloader=on_dataloader,\n",
    "#     val_dataloaders=on_dataloader,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn, vld, tst = get_oneills_dataloaders(\n",
    "#     \"/disk/scratch_fast/s0816700/data/oneills/oneills_reformat.abc\",\n",
    "#     \"/disk/scratch_fast/s0816700/data/folk-rnn/data_v3_vocabulary.txt\",\n",
    "#     batch_size=16,\n",
    "#     num_workers=1,\n",
    "#     pin_memory=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ii in range(len(tst.dataset)):\n",
    "#     print(tst.dataset[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)\n",
    "# lightning_trainer.test(\n",
    "#     model,\n",
    "#     test_dataloaders=tst,\n",
    "# #             ckpt_path=str(args.model_load_from_checkpoint),\n",
    "#     ckpt_path=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
